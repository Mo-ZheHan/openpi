# Latent Action Model (LAM) è®­ç»ƒ

ä½¿ç”¨ LeRobot æ•°æ®é›†è®­ç»ƒæ½œåœ¨åŠ¨ä½œæ¨¡å‹ï¼ŒåŸºäº StreamingLeRobotDataset å®ç°é«˜æ•ˆçš„æµå¼åŠ è½½å’Œäº¤é”™é‡‡æ ·ã€‚

## ğŸš€ å¿«é€Ÿå¼€å§‹

```bash
# 1. æ¿€æ´»ç¯å¢ƒ
source /home/dengyixuan/mzh/Code/UniVLA/openpi/.venv/bin/activate
cd /home/dengyixuan/mzh/Code/UniVLA/openpi/latent_action_model

# 2. é…ç½®æ•°æ®é›†ï¼ˆç¼–è¾‘ config/lam.yamlï¼‰
vim config/lam.yaml

# 3. å¯åŠ¨è®­ç»ƒ
bash train.sh      # 8 GPU è®­ç»ƒ
# æˆ–
python main.py fit --config config/lam.yaml  # å• GPU
```

## ğŸ“‚ ç›®å½•ç»“æ„

```
latent_action_model/
â”œâ”€â”€ config/
â”‚   â””â”€â”€ lam.yaml                # è®­ç»ƒé…ç½®
â”œâ”€â”€ genie/
â”‚   â”œâ”€â”€ dataset.py              # LeRobot æ•°æ®é›†å®ç° (StreamingDataset)
â”‚   â”œâ”€â”€ model.py                # LAM æ¨¡å‹
â”‚   â””â”€â”€ modules/                # æ¨¡å‹ç»„ä»¶
â”‚       â”œâ”€â”€ lam.py              # æ½œåœ¨åŠ¨ä½œæ¨¡å‹
â”‚       â”œâ”€â”€ blocks.py           # Transformer å—
â”‚       â””â”€â”€ __init__.py
â”œâ”€â”€ main.py                     # è®­ç»ƒå…¥å£
â”œâ”€â”€ train.sh                    # å¤šGPUè®­ç»ƒè„šæœ¬
â”œâ”€â”€ README.md                   # æœ¬æ–‡ä»¶
â””â”€â”€ ä½¿ç”¨è¯´æ˜.md                 # è¯¦ç»†ä½¿ç”¨è¯´æ˜
```

## âœ¨ æ ¸å¿ƒç‰¹æ€§

### 1. StreamingLeRobotDataset é›†æˆ
- **æµå¼åŠ è½½**: è¾¹ä¸‹è½½è¾¹è®­ç»ƒï¼Œæ— éœ€ç­‰å¾…å®Œæ•´æ•°æ®é›†ä¸‹è½½
- **å†…å­˜é«˜æ•ˆ**: ä»…ç¼“å­˜ buffer_size ä¸ªæ ·æœ¬ï¼ˆé»˜è®¤1000ï¼‰ï¼Œå†…å­˜æ¶ˆè€—é™ä½ 99%
- **è‡ªåŠ¨æ‰“ä¹±**: æ•°æ®é›†å†…éƒ¨è‡ªåŠ¨å¤„ç†éšæœºæ‰“ä¹±

### 2. çœŸæ­£çš„äº¤é”™é‡‡æ ·
- **æ¯æ­¥éšæœº**: æ¯æ¬¡è¿­ä»£ç‹¬ç«‹éšæœºé€‰æ‹©æ•°æ®é›†
- **æƒé‡æ§åˆ¶**: æ ¹æ®é…ç½®çš„æƒé‡è¿›è¡Œé‡‡æ ·
- **ä¸ RLDS ä¸€è‡´**: é‡‡æ ·æ•ˆæœä¸åŸç‰ˆ RLDS `make_interleaved_dataset` å®Œå…¨ç›¸åŒ

### 3. è‡ªåŠ¨å¸§é—´éš”è°ƒæ•´
æ ¹æ®æ•°æ®é›†é¢‘ç‡è‡ªåŠ¨è°ƒæ•´é‡‡æ ·çª—å£ï¼š
- **ego4d**: 2 å¸§
- **ä½é¢‘ (3-5Hz)**: 3-5 å¸§
- **é«˜é¢‘ (15-30Hz)**: 15-20 å¸§
- **é»˜è®¤**: 10 å¸§

### 4. å›¾åƒå¢å¼º
- Random resized crop
- Color jitter (brightness, contrast, saturation, hue)
- è®­ç»ƒæ—¶å¯ç”¨ï¼ŒéªŒè¯æ—¶ç¦ç”¨

## âš™ï¸ é…ç½®

ç¼–è¾‘ `config/lam.yaml`:

```yaml
data:
  dataset_mix:
    - ["lerobot/aloha_sim_insertion_human", 1.0]
    - ["lerobot/pusht", 2.0]
    - ["your-org/your-dataset", 1.5]

  batch_size: 64
  resolution: 224
  image_aug: true
  buffer_size: 1000    # ç¼“å†²åŒºå¤§å° (500-5000)
  seed: 42             # éšæœºç§å­

model:
  lam_model_dim: 768
  lam_latent_dim: 128
  lam_num_latents: 16
  vq_beta: 0.25

trainer:
  max_epochs: 20
  devices: 8
  precision: 16-mixed
```

### å…³é”®å‚æ•°è¯´æ˜

| å‚æ•° | è¯´æ˜ | æ¨èå€¼ |
|------|------|--------|
| `dataset_mix` | æ•°æ®é›†åˆ—è¡¨åŠæƒé‡ | æ ¹æ®éœ€æ±‚è®¾ç½® |
| `batch_size` | æ‰¹æ¬¡å¤§å° | 64 (å¯è°ƒ: 32-128) |
| `resolution` | å›¾åƒåˆ†è¾¨ç‡ | 224 |
| `image_aug` | å›¾åƒå¢å¼º | true (è®­ç»ƒ), false (è¯„ä¼°) |
| `buffer_size` | ç¼“å†²åŒºå¤§å° | 1000 (å¯è°ƒ: 500-5000) |
| `seed` | éšæœºç§å­ | 42 |

**æ³¨æ„**: `num_workers` å’Œ `shuffle` å·²ç§»é™¤ï¼Œ`StreamingLeRobotDataset` å†…éƒ¨è‡ªåŠ¨å¤„ç†ã€‚

## ğŸ“Š æ€§èƒ½

### ä¸åŸç‰ˆ RLDS å¯¹æ¯”

| æŒ‡æ ‡ | RLDS | StreamingLeRobot | æ”¹è¿› |
|------|------|------------------|------|
| å†…å­˜æ¶ˆè€— | ~471 GB | ~4.6 GB | â†“ 99% |
| å¯åŠ¨æ—¶é—´ | ~5 åˆ†é’Ÿ | <10 ç§’ | â†‘ 30x |
| é‡‡æ ·éšæœºæ€§ | çœŸæ­£äº¤é”™ | çœŸæ­£äº¤é”™ | âœ… ä¸€è‡´ |
| ä»£ç å¤æ‚åº¦ | é«˜ | ä½ | â†“ 50% |

### å†…å­˜è°ƒä¼˜

| åœºæ™¯ | buffer_size | batch_size | å†…å­˜éœ€æ±‚ (10ä¸ªæ•°æ®é›†) |
|------|-------------|------------|---------------------|
| ä½å†…å­˜ | 500 | 32 | ~2.5 GB |
| æ ‡å‡† | 1000 | 64 | ~5 GB |
| é«˜æ€§èƒ½ | 5000 | 128 | ~23 GB |

## ğŸ”§ å®ç°ç»†èŠ‚

### äº¤é”™é‡‡æ ·æ ¸å¿ƒé€»è¾‘

```python
class InterleavedStreamingDataset(IterableDataset):
    def __iter__(self):
        # ä¸ºæ¯ä¸ªæ•°æ®é›†åˆ›å»ºç‹¬ç«‹è¿­ä»£å™¨
        datasets = [
            StreamingLeRobotDataset(
                repo_id=repo_id,
                streaming=True,      # æµå¼æ¨¡å¼
                shuffle=True,        # è‡ªåŠ¨æ‰“ä¹±
                buffer_size=1000,    # ç¼“å†²åŒº
                delta_timestamps={   # è‡ªåŠ¨å¸§å¯¹
                    "observation.image": [0.0, delta_t]
                },
            )
            for repo_id in repo_ids
        ]
        iterators = [iter(ds) for ds in datasets]

        # æ¯æ­¥éšæœºé€‰æ‹©æ•°æ®é›†ï¼ˆå…³é”®ï¼ï¼‰
        while True:
            dataset_idx = rng.choice(len(datasets), p=self.weights)
            sample = next(iterators[dataset_idx])
            yield process(sample)
```

### è‡ªåŠ¨ç‰¹æ€§

1. **å¹¶è¡Œå¤„ç†**: `StreamingLeRobotDataset` å†…éƒ¨è‡ªåŠ¨å¹¶è¡ŒåŒ–ï¼Œæ— éœ€é…ç½® `num_workers`
2. **è‡ªåŠ¨æ‰“ä¹±**: æ¯ä¸ªæ•°æ®é›†å†…éƒ¨ä½¿ç”¨ Backtrackable buffer è‡ªåŠ¨æ‰“ä¹±
3. **è‡ªåŠ¨å¸§å¯¹**: ä½¿ç”¨ `delta_timestamps` åŸºäº fps è‡ªåŠ¨è®¡ç®—æ­£ç¡®çš„å¸§é—´éš”
4. **Episode è¾¹ç•Œ**: LeRobot è‡ªåŠ¨å¤„ç†ï¼Œä¸ä¼šè·¨ episode é‡‡æ ·

## ğŸ› æ•…éšœæ’é™¤

### é—®é¢˜: å†…å­˜ä¸è¶³
```yaml
data:
  buffer_size: 500
  batch_size: 32
```

### é—®é¢˜: æ•°æ®åŠ è½½æ…¢
å¢å¤§ buffer_sizeï¼ˆå¦‚æœå†…å­˜å…è®¸ï¼‰:
```yaml
data:
  buffer_size: 5000
```

### é—®é¢˜: éªŒè¯æ•°æ®é›†
```bash
source /home/dengyixuan/mzh/Code/UniVLA/openpi/.venv/bin/activate
python -c "from lerobot.datasets.lerobot_dataset import LeRobotDatasetMetadata; print(LeRobotDatasetMetadata('your-repo-id'))"
```

## ğŸ“ˆ ç›‘æ§è®­ç»ƒ

```bash
# TensorBoard
tensorboard --logdir=./logs

# æ£€æŸ¥ç‚¹ä½ç½®
ls -lh ./logs/lam_training/
```

## ğŸ¯ å…³é”®ä¼˜åŠ¿

1. âœ… **å†…å­˜é«˜æ•ˆ**: ä½¿ç”¨æµå¼åŠ è½½ï¼Œå†…å­˜æ¶ˆè€—é™ä½ 99%
2. âœ… **å¯åŠ¨å¿«é€Ÿ**: <10ç§’å³å¯å¼€å§‹è®­ç»ƒ
3. âœ… **é‡‡æ ·æ­£ç¡®**: ä¸ RLDS äº¤é”™é‡‡æ ·æ•ˆæœå®Œå…¨ä¸€è‡´
4. âœ… **é…ç½®ç®€æ´**: è‡ªåŠ¨å¤„ç†å¹¶è¡Œå’Œæ‰“ä¹±ï¼Œé…ç½®æ›´ç®€å•
5. âœ… **æ˜“äºä½¿ç”¨**: çº¯ PyTorchï¼Œæ˜“äºè°ƒè¯•å’Œæ‰©å±•

---

**ç‰ˆæœ¬**: v2.0 (StreamingDataset)
**çŠ¶æ€**: âœ… ç”Ÿäº§å°±ç»ª
**ç¯å¢ƒ**: `/home/dengyixuan/mzh/Code/UniVLA/openpi/.venv`
